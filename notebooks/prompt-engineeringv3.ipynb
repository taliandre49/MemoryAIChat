{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "from os import environ\n",
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = openai.OpenAI(\n",
    "#     api_key=environ[\"OPENAI_API_KEY\"],\n",
    "#     base_url=environ[\"OPENAI_ENDPOINT\"]\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='openai.text-embedding-3-large', created=1677610602, object='model', owned_by='openai'), Model(id='cohere.command-r-plus', created=1677610602, object='model', owned_by='openai'), Model(id='cohere.embed-english.v3', created=1677610602, object='model', owned_by='openai'), Model(id='cohere.command-r', created=1677610602, object='model', owned_by='openai'), Model(id='meta.llama-3.2-11b-vision-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='openai.gpt-4o', created=1677610602, object='model', owned_by='openai'), Model(id='amazon.titan-text-embeddings.v2', created=1677610602, object='model', owned_by='openai'), Model(id='openai.gpt-4o-mini', created=1677610602, object='model', owned_by='openai'), Model(id='meta.llama-3.2-90b-vision-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='meta.llama-3.1-405b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='openai.gpt-4o-mini.2024-07-18', created=1677610602, object='model', owned_by='openai'), Model(id='meta.llama-3.2-1b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='meta.llama-3.2-3b-instruct', created=1677610602, object='model', owned_by='openai'), Model(id='anthropic.claude-3.5-haiku', created=1677610602, object='model', owned_by='openai'), Model(id='openai.text-embedding-3-small', created=1677610602, object='model', owned_by='openai'), Model(id='openai.gpt-4o.2024-08-06', created=1677610602, object='model', owned_by='openai'), Model(id='anthropic.claude-3.5-sonnet.v2', created=1677610602, object='model', owned_by='openai')], object='list')\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In twilight's whisper, shadows play,  \n",
      "Stars emerge to greet the day,  \n",
      "Moonbeams dance on silver streams,  \n",
      "Cradling softly our sweetest dreams.  \n",
      "\n",
      "Breezes carry secrets light,  \n",
      "As fireflies blink in the night,  \n",
      "Nature's lullaby, pure and true,  \n",
      "A symphony for me and you.  \n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"openai.gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"this is a test request, write a short poem\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/site-packages (0.8.0)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.11/site-packages (1.0.12)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (from timm) (2.5.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/site-packages (from timm) (0.20.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/site-packages (from timm) (0.27.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/site-packages (from timm) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub->timm) (3.13.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from torchvision->timm) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from datasets) (3.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/site-packages (from accelerate) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: gtts in /usr/local/lib/python3.11/site-packages (2.5.4)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/site-packages (from gtts) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install torch\n",
    "! pip install einops timm\n",
    "! pip install datasets\n",
    "! pip install librosa\n",
    "! pip install soundfile\n",
    "! pip install accelerate\n",
    "! pip install gtts\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM  \n",
    "from PIL import Image\n",
    "from os import environ\n",
    "from io import BytesIO\n",
    "import os\n",
    "import requests\n",
    "import copy\n",
    "import torch\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: This building, with its striking design and dramatic sky, creates a captivating atmosphere! Have you had any memorable experiences at Bates Hall or nearby?\n",
      "\n",
      "Chatbot is ready! Type 'exit' to end the conversation.\n",
      "Assistant: Oh no, I’m sorry to hear that! That must have been quite a painful experience. Can you tell me more about what happened?\n",
      "Assistant: That sounds really tough, especially with the unexpected nature of it! How did you feel in the moments right after the accident?\n",
      "Assistant: I can only imagine how difficult that must have been. Did you have someone with you at the time to help you out?\n",
      "Assistant: That must have felt really overwhelming. It’s tough to go through something like that alone. How did you manage to get the help you needed afterward?\n",
      "Assistant: That was a smart move. It must have been a relief to have help on the way. How did you feel once the paramedics arrived?\n",
      "Assistant: Thank you so much for sharing your memories with me. Is there anything else you'd like to add?\n",
      "Assistant: Thank you for sharing! If you have any more details to add later, feel free to revisit.\n"
     ]
    }
   ],
   "source": [
    "# Initialize conversation history\n",
    "conversation_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"\n",
    "        You are a Retrieval-Augmented Visual Memory Assistant called DejaVu designed to help memory-impaired individuals \n",
    "        enrich their memories and recall details about their experiences. \n",
    "\n",
    "        Your goal is to engage the user in a **natural, conversational manner**. Do not provide lists, \n",
    "        numbered responses, or multiple suggestions in one reply. Keep your answers **clear, concise, and engaging**.\n",
    "\n",
    "        Start by analyzing the provided image description. Summarize it in one positive, friendly sentence, \n",
    "        then follow up with a single conversational question to encourage the user to share more details. \n",
    "        Focus on personal experiences, emotions, and meaningful moments.\n",
    "\n",
    "        Conclude the conversation when you have gathered enough meaningful context by:\n",
    "        - Thanking the user for sharing their memories.\n",
    "        - Asking if there is anything else they would like to add.\n",
    "        - Politely signaling the end of the memory-annotation process if the user has no additional input.\n",
    "\n",
    "        Example:\n",
    "        Input: \"A group of people sitting on the grass in front of a large brick building.\"\n",
    "        Output: \"This looks like such a cheerful day with friends! Can you share where this photo was taken?\"\n",
    "\n",
    "        Additional Instructions:\n",
    "        - Use empathetic and supportive language.\n",
    "        - Avoid repeating questions or providing overly lengthy responses.\n",
    "        - If the user struggles to recall details, gently encourage them without pressure.\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define a function to initialize the conversation with an image description\n",
    "def initialize_conversation(image_description):\n",
    "    \"\"\"\n",
    "    Starts the conversation based on an image description by generating a friendly opening line.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add the image description as the initial user input\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": f\"Image description: {image_description}\"})\n",
    "        \n",
    "        # Make the API call to generate the assistant's initial response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"openai.gpt-4o-mini\",  # Replace with the desired model name\n",
    "            messages=conversation_history,\n",
    "            max_tokens=150,  # Adjust as needed\n",
    "            temperature=0.5  # Lower temperature for more focused output\n",
    "        )\n",
    "        \n",
    "        # Get the assistant's response\n",
    "        assistant_response = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Add the assistant's response to the conversation history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        \n",
    "        return assistant_response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Define a function to continue the chat with the assistant\n",
    "def chat_with_assistant(user_input):\n",
    "    \"\"\"\n",
    "    Sends user input to the OpenAI chat model and returns the assistant's response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add the user input to the conversation history\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        # Make the API call\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"openai.gpt-4o-mini\",  # Replace with the desired model name\n",
    "            messages=conversation_history,\n",
    "            max_tokens=300,  # Adjust as needed\n",
    "            temperature=0.5  # Lower temperature for more consistent responses\n",
    "        )\n",
    "        \n",
    "        # Get the assistant's response\n",
    "        assistant_response = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Add the assistant's response to the conversation history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        \n",
    "        return assistant_response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Start the chatbot loop\n",
    "def run_chatbot(image_description):\n",
    "    # Initialize the conversation with the image description\n",
    "    initial_response = initialize_conversation(image_description)\n",
    "    print(f\"Assistant: {initial_response}\")\n",
    "    \n",
    "    interaction_count = 0\n",
    "    max_interactions = 5  # Define the threshold for interactions\n",
    "    \n",
    "    print(\"\\nChatbot is ready! Type 'exit' to end the conversation.\")\n",
    "    while True:\n",
    "        # Increment interaction count\n",
    "        interaction_count += 1\n",
    "        \n",
    "        # Check if the conversation should conclude\n",
    "        if interaction_count > max_interactions:\n",
    "            print(\"Assistant: Thank you so much for sharing your memories with me. Is there anything else you'd like to add?\")\n",
    "            user_input = input(\"You: \")\n",
    "            \n",
    "            if user_input.strip().lower() in [\"no\", \"nothing else\", \"exit\"]:\n",
    "                print(\"Assistant: I'm glad I could help. Take care and have a wonderful day!\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"Assistant: Thank you for sharing! If you have any more details to add later, feel free to revisit.\")\n",
    "                break\n",
    "        \n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        # Exit the loop if the user types 'exit'\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Assistant: Thank you for chatting with me. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Get the assistant's response\n",
    "        assistant_response = chat_with_assistant(user_input)\n",
    "        \n",
    "        # Print the assistant's response\n",
    "        print(f\"Assistant: {assistant_response}\")\n",
    "\n",
    "# Example usage: Run the chatbot with an image description\n",
    "example_image_description = \"\"\"\n",
    "The image depicts a modern building with a striking design, set against a dramatic sky.\n",
    "\n",
    "**Main Subject and Setting**\n",
    "The building's main subject is its unique architecture, featuring a large glass facade and a cantilevered structure that extends over the entrance. The building is situated in a public space, with a sidewalk leading up to it and a grassy area to the right.\n",
    "\n",
    "**Time of Day and Weather Conditions**\n",
    "The time of day appears to be dusk, as the sky is overcast and dark clouds are visible. The lighting inside the building suggests that it is illuminated from within, possibly due to the setting sun.\n",
    "\n",
    "**Colors and Visual Elements**\n",
    "The building's exterior is primarily composed of glass and metal, with a silver-colored metal cladding that gives it a sleek and contemporary look. The cantilevered structure is supported by thin metal beams, which add to the building's futuristic aesthetic. The sky above is a deep grey, with darker clouds gathering in the distance.\n",
    "\n",
    "**Emotions and Actions**\n",
    "There are no visible emotions or actions in the image, as it appears to be a static photograph of the building.\n",
    "\n",
    "**Significant Objects or Landmarks**\n",
    "The building itself is the most significant object in the image, with its unique design and architecture making it a notable landmark. In the background, a few trees and other buildings can be seen, but they are not as prominent as the main subject.\n",
    "\n",
    "**Text and Signs**\n",
    "The building's name, \"Bates Hall,\" is visible on the front of the structure, just below the cantilevered section. There are no other signs or text visible in the image.\n",
    "\n",
    "**Clothing and Attire**\n",
    "There are no people visible in the image, so there is no clothing or attire to describe.\n",
    "\n",
    "**Surrounding Environment and Background**\n",
    "The surrounding environment is a public space, with a sidewalk leading up to the building and a grassy area to the right. In the background, a few trees and other buildings can be seen, but they are not as prominent as the main subject.\n",
    "\n",
    "**Overall Mood and Atmosphere**\n",
    "\"\"\"\n",
    "run_chatbot(example_image_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resized and saved as 'resized_image.jpg'\n",
      "Full Response: The image depicts a modern building, likely a museum or library, with a striking design that features a combination of glass and metal elements. The building's façade is composed of large glass panels and metal accents, which give it a sleek and contemporary appearance.\n",
      "\n",
      "Here are the key details about the image:\n",
      "\n",
      "1. **Main subject(s) or people in the photo**: There are no people visible in the image.\n",
      "2. **Location or setting**: The building appears to be situated in an urban area, possibly on a college campus or in a downtown district. The presence of a road in front of the building suggests that it is located in a populated area.\n",
      "3. **Time of day and weather conditions**: The sky above the building is cloudy and overcast, indicating that the photo was taken during the late afternoon or early evening. The lighting on the building suggests that the sun is low in the sky, casting a warm glow over the scene.\n",
      "4. **Colors and visual elements that stand out**: The building's metal accents and glass panels create a striking contrast with the surrounding environment. The warm lighting on the building's interior adds a sense of warmth and coziness to the overall scene.\n",
      "5. **Visible emotions or actions**: There are no visible emotions or actions in the image, as it appears to be a static photograph of the building.\n",
      "6. **Significant objects or landmarks**: The building itself is the most prominent feature of the image, but there are also some smaller details that stand out, such as the road in front of the building and the trees or bushes to the left of the image.\n",
      "7. **Text or signs visible in the image**: The word \"GATES HALL\" is visible on the front of the building, suggesting that it may be a university building or a research center.\n",
      "8. **Clothing or attire of people (if applicable)**: As mentioned earlier, there are no people visible in the image.\n",
      "9. **Surrounding environment or background details**: The surrounding environment is relatively barren, with only a few trees or bushes visible in the distance. The road in front of the building suggests that it is located in a populated area, but the lack of other buildings or structures in the immediate vicinity creates a sense of isolation.\n",
      "10. **Overall mood or atmosphere of the scene**: The image conveys a sense of modernity and innovation, thanks to the building's sleek design and contemporary materials. The cloudy sky and warm lighting on the building's interior\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import os\n",
    "\n",
    "# Path to the local image file\n",
    "local_image_path = \"../bill_melinda_gates.jpg\"  # Replace with your local file path\n",
    "\n",
    "# Step 1: Resize the image to fit the model's requirements\n",
    "def resize_image(image_path, max_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    Resize the image to fit within the max_size while maintaining aspect ratio.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img.thumbnail(max_size)  # Resize the image\n",
    "            resized_path = \"resized_image.jpg\"  # Temporary file to save the resized image\n",
    "            img.save(resized_path, format=\"JPEG\")\n",
    "            print(f\"Image resized and saved as '{resized_path}'\")\n",
    "            return resized_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error resizing image: {e}\")\n",
    "        exit()\n",
    "\n",
    "# Step 2: Encode the resized image file as Base64\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Encode the image file as a Base64 string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{image_path}' not found.\")\n",
    "        exit()\n",
    "\n",
    "# Step 3: Send the Base64 image to the OpenAI endpoint\n",
    "def send_image_to_openai(base64_image):\n",
    "    \"\"\"\n",
    "    Send the Base64-encoded image to the OpenAI endpoint.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        full_response = \"\"\n",
    "        prompt = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}},\n",
    "                {\"type\": \"text\", \"text\": \"\"\"Describe the image in detail, focusing on the following aspects: \n",
    "                 1. Main subject(s) or people in the photo, \n",
    "                 2. Location or setting, \n",
    "                 3. Time of day and weather conditions, \n",
    "                 4. Colors and visual elements that stand out, \n",
    "                 5. Any visible emotions or actions, \n",
    "                 6. Significant objects or landmarks, \n",
    "                 7. Any text or signs visible in the image, \n",
    "                 8. Clothing or attire of people (if applicable), \n",
    "                 9. Surrounding environment or background details, \n",
    "                 10. Overall mood or atmosphere of the scene, Please provide a comprehensive description that captures both the visual elements and the context of the image, as if explaining it to someone who cannot see it. \n",
    "                 Include any details that might be particularly memorable or emotionally significant.\"\"\"}\n",
    "            ]}\n",
    "        ]\n",
    "        while True:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"meta.llama-3.2-11b-vision-instruct\",  # Replace with your model name\n",
    "                messages=prompt,\n",
    "                max_tokens=500,  # Adjust as needed\n",
    "                temperature=0.7\n",
    "            )\n",
    "            response_content = response.choices[0].message.content\n",
    "#            print(response_content)\n",
    "            full_response += response_content\n",
    "            \n",
    "            # Check if the response ends abruptly and prompt continuation\n",
    "            if not response_content.strip().endswith(\"...\"):\n",
    "                break  # No continuation needed\n",
    "            prompt = [{\"role\": \"assistant\", \"content\": \"Continue describing the image.\"}]\n",
    "        \n",
    "        print(\"Full Response:\", full_response)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "# Workflow\n",
    "resized_image_path = resize_image(local_image_path, max_size=(512, 512))  # Resize the image\n",
    "base64_image = encode_image_to_base64(resized_image_path)  # Encode resized image\n",
    "send_image_to_openai(base64_image)  # Send the image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
